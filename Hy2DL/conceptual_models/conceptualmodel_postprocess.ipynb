{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hydrological models were calibrated using 2 different methods. In this notebook we select the best calibration set for each basin, and get the variables of interest for each case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Import necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from hydrological_models import SHM, bucket, NonSense\n",
    "from spotpy_calibration import read_information\n",
    "from spotpy_calibration import NSE_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize information\n",
    "model = 'SHM' # change to 'SHM' 'bucket' 'NonSense' depending on which results you want to generate\n",
    "path_data = '../results/conceptual_models/'\n",
    "path_ts = '../../data/CAMELS_GB/timeseries/'\n",
    "warmup = 365\n",
    "forcing_variables = ['precipitation', 'peti', 'temperature']\n",
    "target_variables = ['discharge_spec']\n",
    "testing_period = ['1997-01-01','2008-12-31']\n",
    "\n",
    "hyd_model = SHM() # change to 'SHM' 'bucket' 'NonSense' depending on which results you want to generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the calibration results by each method, and select the best case. In other words, select the calibrated\n",
    "# parameters (for each basin) that gave best results. The SHM_XXX_summary.csv files are generated when running the \n",
    "# scripts associated with each calibration method\n",
    "\n",
    "# Read DREAM calibration\n",
    "df_dream = pd.read_csv(path_data + model + '_dream_summary.csv', dtype={'basin_id': str})\n",
    "df_dream.set_index('basin_id', inplace=True)\n",
    "\n",
    "# Read SCE calibration\n",
    "df_sce = pd.read_csv(path_data + model + '_sce_summary.csv', dtype={'basin_id': str})\n",
    "df_sce.set_index('basin_id', inplace=True)\n",
    "\n",
    "# The last column of each dataset is the NSE in testing.\n",
    "last_column_values = pd.concat([df_dream.iloc[:, -1], df_sce.iloc[:, -1]], axis=1,  keys=['dream', 'sce'])\n",
    "\n",
    "max_value_index = last_column_values.idxmax(axis=1)\n",
    "\n",
    "# Select the best parameter set for each basin\n",
    "parameter_sets = pd.concat([df_dream[max_value_index=='dream'].iloc[:, 1:-1], \n",
    "                            df_sce[max_value_index=='sce'].iloc[:, 1:-1]], axis=0)\n",
    "\n",
    "\n",
    "parameter_sets= parameter_sets.reindex(df_dream.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the model for each basin, using the best calibration parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = {}\n",
    "NSE_testing =  []\n",
    "\n",
    "time_index= pd.date_range(start=testing_period[0], end=testing_period[1])\n",
    "# Loop that goes through each basin\n",
    "for i, basin in enumerate(df_dream.index):\n",
    "     \n",
    "     input, target = read_information(path_ts = path_ts, \n",
    "                                     basin_id = basin, \n",
    "                                     forcing = forcing_variables, \n",
    "                                     target = target_variables, \n",
    "                                     time_period = testing_period)\n",
    "     \n",
    "     \n",
    "     out, states = hyd_model.run_model(input=input, param=parameter_sets.loc[basin].values)\n",
    "     \n",
    "     \n",
    "     \n",
    "     df_discharge = pd.DataFrame(data={'discharge': out[warmup:,:].flatten()}, index=time_index[warmup:])\n",
    "     \n",
    "     internal_states = {key: value[warmup:, :].flatten() for key, value in states.items()}\n",
    "     df_buckets = pd.DataFrame(data=internal_states, index=time_index[warmup:]) \n",
    "\n",
    "\n",
    "     test_results[basin] = {'discharges': df_discharge,\n",
    "                            'internal_states': df_buckets}\n",
    "       \n",
    "     NSE_testing.append(NSE_loss(evaluation=target[warmup:][~np.isnan(target)[warmup:,0]].flatten(),\n",
    "                                 simulation=out[warmup:][~np.isnan(target)[warmup:,0]].flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final NSE for testing period for all basins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NSE = pd.DataFrame(data={'basin_id': df_dream.index,'NSE': NSE_testing})\n",
    "df_NSE = df_NSE.set_index('basin_id')\n",
    "df_NSE.to_csv(path_data+'/'+model+'_NSE_669.csv', index=True, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate soil moisture series of SHM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate soil moisture series\n",
    "bucket_name = 'su'\n",
    "buckets =  {key: value['internal_states'][bucket_name] for key, value in test_results.items()}\n",
    "df_buckets = pd.DataFrame(data=buckets)\n",
    "df_buckets.index.name = 'date'\n",
    "df_buckets.to_csv(path_data+'/'+model+'_'+bucket_name+'.csv', index=True, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "42b7dc197ee81dd2f6541889b0e14556b882d218c1e7c97db94bc0f7b191f034"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
