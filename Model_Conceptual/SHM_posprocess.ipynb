{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SHM model was calibrated using 3 different methods. In this notebook we select the best calibration set for each basin, and get the variables of interest for each case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Import necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for the hydrological model\n",
    "def run_SHM(X_SHM, initial_states, param):\n",
    "\n",
    "    #read initial states and parameters\n",
    "    ss, sf, su, si, sb = initial_states\n",
    "    dd, f_thr, sumax, beta, perc, kf, ki, kb = param \n",
    "\n",
    "    # initialize vector to store variables of interest\n",
    "    q_out = np.zeros((X_SHM.shape[0], 1)) # final discharge\n",
    "    states = np.zeros((X_SHM.shape[0], 5)) # internal states (buckets)\n",
    "    outflows = np.zeros((X_SHM.shape[0], 3)) # discharge coming from each bucket\n",
    "\n",
    "    # run model for each timestep\n",
    "    for i, (p, pet, temp) in enumerate(X_SHM):\n",
    "        \n",
    "        # Snow module --------------------------\n",
    "        if temp > 0: # if there is snowmelt\n",
    "            qs_out = min(ss, dd*temp) # snowmelt from snow reservoir\n",
    "            ss = ss - qs_out # substract snowmelt from snow reservoir\n",
    "            qsp_out = qs_out + p # flow from snowmelt and rainfall\n",
    "        else: # if the is no snowmelt\n",
    "            ss=ss + p # precipitation accumalates as snow in snow reservoir\n",
    "            qsp_out = 0.0\n",
    "\n",
    "        # Split snowmelt+rainfall into inflow to fastflow reservoir and unsaturated reservoir ------\n",
    "        qf_in = max(0, qsp_out-f_thr)\n",
    "        qu_in = min(qsp_out, f_thr)\n",
    "\n",
    "        # Fastflow module ----------------------\n",
    "        sf = sf + qf_in\n",
    "        qf_out = sf/ kf\n",
    "        sf = sf - qf_out\n",
    "\n",
    "        # Unsaturated zone----------------------\n",
    "        psi = (su / sumax) ** beta #[-]\n",
    "        su_temp = su + qu_in * (1 - psi)\n",
    "        su = min(su_temp, sumax)\n",
    "        qu_out = qu_in * psi + max(0.0, su_temp - sumax) # [mm]\n",
    "        \n",
    "        # Evapotranspiration -------------------\n",
    "        klu = 0.9 # land use correction factor [-]\n",
    "        if su <= 0.0:\n",
    "            ktetha = 0.0\n",
    "        elif su >= 0.8 * sumax:\n",
    "            ktetha = 1.0\n",
    "        else:\n",
    "            ktetha = su / sumax\n",
    "\n",
    "        ret = pet * klu * ktetha #[mm]\n",
    "        su = max(0.0, su - ret) #[mm]\n",
    "\n",
    "        # Interflow reservoir ------------------\n",
    "        qi_in = qu_out * perc #[mm]\n",
    "        si = si + qi_in #[mm]\n",
    "        qi_out = si / ki #[mm]\n",
    "        si = si - qi_out #[mm]\n",
    "\n",
    "        # Baseflow reservoir -------------------\n",
    "        qb_in = qu_out * (1 - perc) #[mm]\n",
    "        sb = sb + qb_in #[mm]\n",
    "        qb_out = sb / kb #[mm]\n",
    "        sb = sb - qb_out #[mm]\n",
    "\n",
    "        # Output\n",
    "        q_out[i,0] = qf_out + qi_out + qb_out #[mm]\n",
    "        states[i,:] = np.hstack((ss, sf, su, si, sb))\n",
    "        outflows[i,:] = np.hstack((qf_out, qi_out, qb_out))\n",
    "\n",
    "    return q_out, states, outflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "def nse_loss(sim, obs):\n",
    "    nse_loss = np.sum((sim - obs)**2) / np.sum((obs - np.mean(obs))**2)\n",
    "    return np.round(1.0-nse_loss,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize information\n",
    "path_basins= '../data/CAMELS-GB/timeseries_v2/Selected_Basins_hybrid.csv'\n",
    "path_ts = '../data/CAMELS-GB/timeseries_v2/'\n",
    "path_SHM_data = '../results/models/SHM/'\n",
    "\n",
    "buffer = 365 #warmup period\n",
    "initial_conditions = [0.0, 1.0, 5.0, 10.0, 15.0] # (not too important because there is 1 year of warmup)\n",
    "forcing=['date','precipitation', 'peti', 'temperature']\n",
    "target=['date', 'discharge_spec']\n",
    "\n",
    "#all the comparisons are made in testing period\n",
    "testing_period = ['2005-10-01','2012-09-30']\n",
    "\n",
    "# Read information\n",
    "selected_basins_id= list(np.loadtxt(path_basins, skiprows=1).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the calibration results by each method, and select the best case. In other words, select the calibrated\n",
    "# parameters (for each basin) that gave best results.\n",
    "\n",
    "# Note: The SHM_XXX_calibration files are generating when running the scripts associated with each calibration method\n",
    "\n",
    "# Read DREAM calibration\n",
    "df_DREAM = pd.read_csv(path_SHM_data+'SHM_DREAM_calibration.csv')\n",
    "df_DREAM.set_index('basin_id', inplace=True)\n",
    "\n",
    "# Read SCE calibration\n",
    "df_SCE = pd.read_csv(path_SHM_data+'SHM_SCE_calibration.csv')\n",
    "df_SCE.set_index('basin_id', inplace=True)\n",
    "\n",
    "# Read SGD calibration\n",
    "df_SGD = pd.read_csv(path_SHM_data+'SHM_SGD_calibration.csv')\n",
    "df_SGD.set_index('basin_id', inplace=True)\n",
    "\n",
    "# The last column of each dataset is the NSE in testing.\n",
    "last_column_values = pd.concat([df_DREAM.iloc[:, -1], df_SCE.iloc[:, -1], df_SGD.iloc[:, -1]], axis=1,  keys=['DREAM', 'SCE', 'SGD'])\n",
    "max_value_index = last_column_values.idxmax(axis=1)\n",
    "\n",
    "# Select the best parameter set for each basin\n",
    "parameter_sets = pd.concat([df_DREAM[max_value_index=='DREAM'].iloc[:, 1:],\n",
    "                            df_SCE[max_value_index=='SCE'].iloc[:, 1:],\n",
    "                            df_SGD[max_value_index=='SGD'].iloc[:, 1:]], axis=0)\n",
    "\n",
    "parameter_sets= parameter_sets.reindex(selected_basins_id)\n",
    "parameter_sets.to_csv(path_SHM_data+'SHM_calibration.csv', index=True, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the model for each basin, using the best calibration parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing of basin:1/60 with ID:2001 is completed-------------------------------\n",
      "Testing of basin:2/60 with ID:4001 is completed-------------------------------\n",
      "Testing of basin:3/60 with ID:6007 is completed-------------------------------\n",
      "Testing of basin:4/60 with ID:7001 is completed-------------------------------\n",
      "Testing of basin:5/60 with ID:7002 is completed-------------------------------\n",
      "Testing of basin:6/60 with ID:8004 is completed-------------------------------\n",
      "Testing of basin:7/60 with ID:8005 is completed-------------------------------\n",
      "Testing of basin:8/60 with ID:8006 is completed-------------------------------\n",
      "Testing of basin:9/60 with ID:9002 is completed-------------------------------\n",
      "Testing of basin:10/60 with ID:10003 is completed-------------------------------\n",
      "Testing of basin:11/60 with ID:11001 is completed-------------------------------\n",
      "Testing of basin:12/60 with ID:11003 is completed-------------------------------\n",
      "Testing of basin:13/60 with ID:12001 is completed-------------------------------\n",
      "Testing of basin:14/60 with ID:12002 is completed-------------------------------\n",
      "Testing of basin:15/60 with ID:13007 is completed-------------------------------\n",
      "Testing of basin:16/60 with ID:13008 is completed-------------------------------\n",
      "Testing of basin:17/60 with ID:15006 is completed-------------------------------\n",
      "Testing of basin:18/60 with ID:15007 is completed-------------------------------\n",
      "Testing of basin:19/60 with ID:15012 is completed-------------------------------\n",
      "Testing of basin:20/60 with ID:15016 is completed-------------------------------\n",
      "Testing of basin:21/60 with ID:15025 is completed-------------------------------\n",
      "Testing of basin:22/60 with ID:16001 is completed-------------------------------\n",
      "Testing of basin:23/60 with ID:16004 is completed-------------------------------\n",
      "Testing of basin:24/60 with ID:18003 is completed-------------------------------\n",
      "Testing of basin:25/60 with ID:21006 is completed-------------------------------\n",
      "Testing of basin:26/60 with ID:21009 is completed-------------------------------\n",
      "Testing of basin:27/60 with ID:21022 is completed-------------------------------\n",
      "Testing of basin:28/60 with ID:23004 is completed-------------------------------\n",
      "Testing of basin:29/60 with ID:25001 is completed-------------------------------\n",
      "Testing of basin:30/60 with ID:27001 is completed-------------------------------\n",
      "Testing of basin:31/60 with ID:27003 is completed-------------------------------\n",
      "Testing of basin:32/60 with ID:27007 is completed-------------------------------\n",
      "Testing of basin:33/60 with ID:27021 is completed-------------------------------\n",
      "Testing of basin:34/60 with ID:27034 is completed-------------------------------\n",
      "Testing of basin:35/60 with ID:27041 is completed-------------------------------\n",
      "Testing of basin:36/60 with ID:27071 is completed-------------------------------\n",
      "Testing of basin:37/60 with ID:27080 is completed-------------------------------\n",
      "Testing of basin:38/60 with ID:28015 is completed-------------------------------\n",
      "Testing of basin:39/60 with ID:28018 is completed-------------------------------\n",
      "Testing of basin:40/60 with ID:28024 is completed-------------------------------\n",
      "Testing of basin:41/60 with ID:28067 is completed-------------------------------\n",
      "Testing of basin:42/60 with ID:28080 is completed-------------------------------\n",
      "Testing of basin:43/60 with ID:28085 is completed-------------------------------\n",
      "Testing of basin:44/60 with ID:33022 is completed-------------------------------\n",
      "Testing of basin:45/60 with ID:33034 is completed-------------------------------\n",
      "Testing of basin:46/60 with ID:33039 is completed-------------------------------\n",
      "Testing of basin:47/60 with ID:36006 is completed-------------------------------\n",
      "Testing of basin:48/60 with ID:38001 is completed-------------------------------\n",
      "Testing of basin:49/60 with ID:39002 is completed-------------------------------\n",
      "Testing of basin:50/60 with ID:39008 is completed-------------------------------\n",
      "Testing of basin:51/60 with ID:39010 is completed-------------------------------\n",
      "Testing of basin:52/60 with ID:39016 is completed-------------------------------\n",
      "Testing of basin:53/60 with ID:39021 is completed-------------------------------\n",
      "Testing of basin:54/60 with ID:39034 is completed-------------------------------\n",
      "Testing of basin:55/60 with ID:40003 is completed-------------------------------\n",
      "Testing of basin:56/60 with ID:42004 is completed-------------------------------\n",
      "Testing of basin:57/60 with ID:43007 is completed-------------------------------\n",
      "Testing of basin:58/60 with ID:43008 is completed-------------------------------\n",
      "Testing of basin:59/60 with ID:43009 is completed-------------------------------\n",
      "Testing of basin:60/60 with ID:44001 is completed-------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Lists to store the results for each basin\n",
    "NSE_testing = []\n",
    "storages_testing = []\n",
    "outflow_testing = []\n",
    "\n",
    "# Loop that goes through each basin\n",
    "for i, basin in enumerate(selected_basins_id):\n",
    "     \n",
    "     # read input and target for the basin of interest\n",
    "     path_timeseries = path_ts + 'CAMELS_GB_hydromet_timeseries_' + str(basin) + '.csv'\n",
    "     df_ts = pd.read_csv(path_timeseries)  \n",
    "     df_forcing = df_ts.loc[:, forcing]\n",
    "     df_forcing = df_forcing.set_index('date')\n",
    "     df_target = df_ts.loc[:, target]\n",
    "     df_target = df_target.set_index('date')\n",
    "\n",
    "     # Run SHM for testing period using the calibrated parameters\n",
    "     df_forcing = df_forcing.loc[testing_period[0]:testing_period[1]]\n",
    "     df = parameter_sets.loc[basin]\n",
    "     param = np.ndarray.flatten(df.iloc[:-1].values).tolist()\n",
    "     q_sim, states, outflow = run_SHM(df_forcing.to_numpy(), initial_conditions, param)\n",
    "     \n",
    "     # Observations for testing subset\n",
    "     df_target = df_target.loc[testing_period[0]:testing_period[1]]\n",
    "     q_obs = df_target.to_numpy().reshape((-1,1))\n",
    "     \n",
    "     # Calculate NSE in testing\n",
    "     NSE_testing.append(nse_loss(sim=q_sim[buffer:].flatten(), obs=q_obs[buffer:].flatten()))\n",
    "     \n",
    "     #Store infromation of interest\n",
    "     storages_testing.append(states[buffer:,:])\n",
    "     outflow_testing.append(outflow[buffer:,:])\n",
    "     \n",
    "     # Print report\n",
    "     print('Testing of basin:'+str(i+1)+'/'+str(len(selected_basins_id))+' with ID:'+str(basin)+' is completed-------------------------------')\n",
    "\n",
    "# Export NSE of different basins to a txt\n",
    "aux= [list(selected_basins_id), list(NSE_testing)]\n",
    "df_NSE= pd.DataFrame(list(zip(*aux)), columns=['basin_id', 'NSE_SHM'])\n",
    "df_NSE = df_NSE.set_index('basin_id')\n",
    "df_NSE.to_csv(path_SHM_data+'NSE_SHM.txt', index=True, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate soil moisture series of SHM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate soil moisture series\n",
    "df_sm = pd.DataFrame()\n",
    "\n",
    "# Iterate over each station_id\n",
    "for i, station_id in enumerate(selected_basins_id):\n",
    "    #Change index of second list according to the reservoir of interest (ss, sf, su, si, sb)\n",
    "    sm_series = storages_testing[i][:,2]\n",
    "    df_sm[station_id] = sm_series\n",
    "    \n",
    "df_sm.index = df_forcing.loc['2006-10-01':'2012-09-30'].index\n",
    "df_sm = df_sm.rename_axis('time') #to be consistent with the era5-land data\n",
    "df_sm.to_csv(path_SHM_data+'SHM_sm.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flux division between the reservoirs (used later for analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qf    0.03\n",
      "qi    0.66\n",
      "qb    0.31\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty list to store DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Iterate over each station_id\n",
    "for i, station_id in enumerate(selected_basins_id):\n",
    "\n",
    "    # Total ouflow coming out of each reservoir (for a given basin)\n",
    "    outflow_series = np.sum(outflow_testing[i], axis=0)\n",
    "    # Relative outflow coming out of each reservoir (for a given basin)\n",
    "    percentage = outflow_series / np.sum(outflow_series)\n",
    "\n",
    "    # Create a DataFrame for the current station_id\n",
    "    data = {'basin_id': [station_id], 'qf': [percentage[0]], 'qi': [percentage[1]], 'qb': [percentage[2]]}\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Append the DataFrame to the list\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames in the list\n",
    "df_discharges = pd.concat(dfs, ignore_index=True)\n",
    "df_discharges.set_index('basin_id', inplace=True)\n",
    "\n",
    "# Calculate the mean values over all the basins\n",
    "print(df_discharges.mean().round(2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "42b7dc197ee81dd2f6541889b0e14556b882d218c1e7c97db94bc0f7b191f034"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
